# -*- coding: utf-8 -*-
"""Telco EDA ( XGBoost )

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10kXKV8VcpN8eyxKaPePt9_dvkZh0nkIF

# Customer churn - Telco

## import and settings
"""

import kagglehub
import pandas as pd
import numpy as np
import os
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.utils import resample
from sklearn.metrics import classification_report, confusion_matrix

"""**Plotty setting**"""

# Set Plotly as Pandas plotting backend

pd.options.plotting.backend = "plotly"
np.set_printoptions(precision=2, suppress=True)
pd.options.display.precision = 2
pd.options.display.float_format = '{:.2f}'.format

"""## Data collection"""

# הורדת הדאטהסט מקגל
path = kagglehub.dataset_download("blastchar/telco-customer-churn")
print("Path to dataset files:", path)

# קריאת הקובץ
df = pd.read_csv(f"{path}/WA_Fn-UseC_-Telco-Customer-Churn.csv")

"""**Dataframe Info**"""

# הצגת מידע ראשוני
print(df.head())
print(df.info())
print(df.describe(include="all"))

"""### **Missing values**"""

# בדיקה של חוסרים
print("Missing values per column:")
print(df.isnull().sum())

"""### **Target values counter**"""

#  בדיקת חלוקת target 'Churn' ===
print("\nחלוקת target - Churn:")
print(df['Churn'].value_counts())
# גרף חלוקת churn
sns.countplot(x='Churn', data=df)
plt.title("Churn Distribution")
plt.show()

"""### **convert Strings to numbers if necessary**"""

import pandas as pd
import numpy as np

def clean_object_numeric(df, fill_numeric=np.nan):
    """
    מנקה עמודות מסוג object:
    - מסיר רווחים מסביב למחרוזת
    - מחליף מחרוזות ריקות ב-NaN
    - מנסה להמיר למספר (float)
    - אם לא ניתן, נשאר object
    - ניתן לציין fill_numeric לערכים ריקים אחרי המרה (default NaN)

    מחזיר DataFrame חדש.
    """
    df = df.copy()
    obj_cols = df.select_dtypes(include=['object']).columns.tolist()

    for col in obj_cols:
        # מסיר רווחים מסביב למחרוזת
        df[col] = df[col].astype(str).str.strip()

        # רווחים ריקים הופכים ל-NaN
        df[col].replace('', np.nan, inplace=True)

        # מנסה להמיר למספר
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            # מילוי ערכים ריקים אם רוצים
            if fill_numeric is not np.nan:
                df[col].fillna(fill_numeric, inplace=True)
            print(f"Column '{col}' converted to numeric")
        except:
            # לא ניתן להמיר → נשאר object
            print(f"Column '{col}' kept as object")

    return df

df = clean_object_numeric(df, fill_numeric=0)

"""### **Feature engineering**"""

import pandas as pd
import numpy as np

def fe_total_charges(df, col='TotalCharges', n_bins=15):
    """
    מנקה את העמודה TotalCharges, ממיר לכל float, ממלא ערכים חסרים ב-0.
    מוסיף עמודות עם bins של TotalCharges.
    מחזיר df עם העמודה המקורית מעודכנת ועמודות הבינים.
    """
    df = df.copy()

    # החלפת רווחים או empty string ל-NaN
    df[col] = df[col].replace(" ", np.nan)

    # המרה ל-float
    df[col] = df[col].astype(float)

    # מילוי NaN ב-0 (אפשר גם עם median או mean)
    df[col] = df[col].fillna(0)

    # יצירת bins
    bin_labels = [f'{col}_bin_{i}' for i in range(n_bins)]
    df_bins = pd.get_dummies(pd.cut(df[col], bins=n_bins, labels=bin_labels, include_lowest=True))

    # איחוד עם df המקורי
    df = pd.concat([df, df_bins], axis=1)

    print(f"Feature Engineering done for '{col}': converted to float and added {n_bins} bins.")
    return df

# שימוש
df = fe_total_charges(df, col='TotalCharges', n_bins=15)

# --- 2. פיצ'ר אינג'ינירינג (יישום ההצעות) ---
print("Applying feature engineering...")

# יצירת פיצ'ר AverageMonthlyCharge
df['AverageMonthlyCharge'] = df['TotalCharges'] / df['tenure']
# טיפול בערכים אינסופיים (עבור tenure=0)
df['AverageMonthlyCharge'].replace([np.inf, -np.inf], 0, inplace=True)
df['AverageMonthlyCharge'].fillna(0, inplace=True)

# קיטוע tenure לקטגוריות
df['tenure_group'] = pd.cut(df['tenure'],
                           bins=[0, 12, 24, 48, np.inf],
                           labels=['0-12', '13-24', '25-48', '49+'],
                           right=False)

# יצירת פיצ'ר HasInternetService
df['HasInternetService'] = df['InternetService'].apply(
    lambda x: 1 if x in ['DSL', 'Fiber optic'] else 0
)

# יצירת פיצ'ר Num_Extra_Services
extra_services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']
# נניח שכל הפיצ'רים הללו מקודדים כ'Yes' או 'No'
df['Num_Extra_Services'] = df[extra_services].apply(
    lambda row: sum(1 for service in row if service == 'Yes'), axis=1
)

# יצירת אינטראקציה בין SeniorCitizen ו-Contract
df['SeniorCitizen_x_Contract'] = df.apply(
    lambda row: f"{row['SeniorCitizen']}_{row['Contract']}", axis=1
)

df.info()

"""###**Print distributions**"""

df.drop(columns=['customerID'], inplace=True)
# מספריות: כל סוגי int ו-float
num_cols = df.select_dtypes(include=['number']).columns.tolist()

# קטגוריות: כל סוגי object ו-category
target = 'Churn'
cat_cols = [c for c in df.select_dtypes(include=['object', 'category']).columns if c != target]

# גרפים בסיסיים על פיצ'רים מספריים
for col in num_cols:
    plt.figure(figsize=(6,3))
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.show()

# גרפים בסיסיים על פיצ'רים קטגוריאליים
for col in cat_cols:
    plt.figure(figsize=(6,3))
    sns.countplot(x=col, data=df)
    plt.title(f'Distribution of {col}')
    plt.show()

"""### **Correlation between Numberical features**"""

# קורלציה בין פיצ'רים מספריים
plt.figure(figsize=(10,6))
corr = df.corr(numeric_only=True)
plt.imshow(corr, cmap='coolwarm', interpolation='none')
plt.colorbar()
plt.xticks(range(len(corr)), corr.columns, rotation=90)
plt.yticks(range(len(corr)), corr.columns)
plt.title("Correlation Heatmap")
plt.show()

"""## Preproccesing"""

def ensure_binary_target(df, target='Churn'):
    """
    בודק שהעמודה target היא בינארית (0/1 או bool).
    אם לא – ממיר את הערכים ל-0/1 לפי unique values.
    מחזיר את הדאטה-פריים עם העמודה מעודכנת.
    """
    import pandas as pd

    # בדיקה אם העמודה קיימת
    if target not in df.columns:
        raise ValueError(f"Column '{target}' not found in DataFrame")

    # בדיקה אם כבר bool או 0/1
    unique_vals = df[target].dropna().unique()

    # אם bool או int 0/1
    if set(unique_vals).issubset({0,1, True, False}):
        return df  # הכל בסדר, מחזירים כמו שהוא

    # אחרת, ממירים ל-0/1
    # ממיר כל ערך ייחודי ל-0 או 1 לפי סדר
    mapping = {val: idx for idx, val in enumerate(sorted(unique_vals))}
    df[target] = df[target].map(mapping).astype(int)
    df = df.rename(columns={target: target})  # זה מוודא שהשם נשאר כמו שהיה

    print(f"Converted '{target}' to binary 0/1 with mapping: {mapping}")
    return df

df = ensure_binary_target(df, target='Churn')

# split
from sklearn.model_selection import train_test_split


X = df.drop(columns=['Churn'])
y = df['Churn']

X = pd.get_dummies(X, columns=cat_cols)


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# סקיילינג (fit רק על train, transform גם על test)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train[num_cols])
joblib.dump(scaler, '../preprocessing/telco/telco_scaler.pkl')

X_test_scaled = scaler.transform(X_test[num_cols])

import json
# 2. שמירת רשימת העמודות הסופית
final_columns = X_train.columns.tolist()
with open('../preprocessing/telco/telco_columns.json', 'w') as f:
    json.dump(final_columns, f)
print("Column list saved to telco_columns.json")

# מחליפים את הערכים המקוריים בסקיילינג
X_train.loc[:, num_cols] = X_train_scaled
X_test.loc[:, num_cols] = X_test_scaled
# איזון מחלקות עם SMOTE (רק על train)
from imblearn.over_sampling import SMOTE


sm = SMOTE(random_state=42, sampling_strategy=0.5)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

print(f"Original training data shape: {X_train.shape}, Class distribution: {y_train.value_counts()}")
print(f"Resampled training data shape: {X_train_res.shape}, Class distribution: {y_train_res.value_counts()}")

"""## **Train model**"""

eval_set = [(X_train, y_train), (X_test, y_test)]

xgb_model = xgb.XGBClassifier(
    n_estimators=300,
    learning_rate=0.01,
    max_depth=4,
    subsample=0.7,
    reg_lambda=1.0,
    reg_alpha=0.5,
    colsample_bytree=0.7,
    scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),  # איזון בין מחלקות
    random_state=42,
    use_label_encoder=False,
    eval_metric=["auc","logloss"]
)

xgb_model.fit(
    X_train,
    y_train,
    eval_set=eval_set,
    verbose=False
)
# --- חיזוי על סט טסט ---
y_pred = xgb_model.predict(X_test)

print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]

print("ROC AUC:", roc_auc_score(y_test, y_pred_proba))

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, label="XGBoost (AUC = %.3f)" % roc_auc_score(y_test, y_pred_proba))
plt.plot([0,1],[0,1],"--", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# עכשיו אפשר לשלוף תוצאות
results = xgb_model.evals_result()

# גרף logloss
epochs = len(results['validation_0']['logloss'])
x_axis = range(0, epochs)

plt.figure(figsize=(8,5))
plt.plot(x_axis, results['validation_0']['logloss'], label='Train')
plt.plot(x_axis, results['validation_1']['logloss'], label='Test')
plt.xlabel("Rounds")
plt.ylabel("Logloss")
plt.title("XGBoost Logloss (Train vs Test)")
plt.legend()
plt.show()


# נניח שהמודל שלך נקרא model
joblib.dump(xgb_model, "../saved_models/telco.pkl")   # בדאטהסט הבנק
# 4. שמירת רשימת העמודות המספריות (חשוב ל-scaler)
with open('../preprocessing/telco/telco_numerical_cols.json', 'w') as f:
    json.dump(num_cols, f)
print("Numerical columns list saved to telco_numerical_cols.json")
from xgboost import plot_importance
import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plot_importance(xgb_model, max_num_features=20, importance_type='gain')  # gain = contribution
plt.show()

import shap

# Explainer ל-XGBoost
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# גרף Summary (תמונה כוללת של כל הפיצ'רים)
shap.summary_plot(shap_values, X_test, plot_type="bar")

# גרף לכל דוגמא ספציפית
shap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:])