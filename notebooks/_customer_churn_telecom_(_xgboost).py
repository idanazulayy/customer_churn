# -*- coding: utf-8 -*-
"""# Customer churn - Telecom ( XGBoost)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cgwzt1Wgd4dfJEZV1oigtj2Warojz0qX

# Customer churn - Telecom

## import and settings
"""

import kagglehub
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.utils import resample
from sklearn.metrics import classification_report, confusion_matrix

"""**Plotty setting**"""

# Set Plotly as Pandas plotting backend

pd.options.plotting.backend = "plotly"
np.set_printoptions(precision=2, suppress=True)
pd.options.display.precision = 2
pd.options.display.float_format = '{:.2f}'.format

"""## Data collection"""

# Download latest version
path = kagglehub.dataset_download("mnassrib/telecom-churn-datasets")

print("Path to dataset files:", path)

# === 2. קריאת הדאטה ===
train_path = "/Users/idanazulay/.cache/kagglehub/datasets/mnassrib/telecom-churn-datasets/versions/1/churn-bigml-80.csv"
test_path  = "/Users/idanazulay/.cache/kagglehub/datasets/mnassrib/telecom-churn-datasets/versions/1/churn-bigml-20.csv"
df_train = pd.read_csv(train_path)
df_test  = pd.read_csv(test_path)


# הצגת מידע ראשוני
print(df_train.head())
print(df_train.info())
print(df_train.describe(include="all"))

"""### **Missing values**"""

# בדיקה של חוסרים
print("Missing values per column:")
print(df_train.isnull().sum())
print(df_test.isnull().sum())

"""### **Target values counter**"""

#  בדיקת חלוקת target 'Churn' ===
print("\nחלוקת target - Churn:")
print(df_train['Churn'].value_counts())
# גרף חלוקת churn
sns.countplot(x='Churn', data=df_train)
plt.title("Churn Distribution")
plt.show()

#  בדיקת חלוקת target 'Churn' ===
print("\nחלוקת target - Churn:")
print(df_test['Churn'].value_counts())
# גרף חלוקת churn
sns.countplot(x='Churn', data=df_test)
plt.title("Churn Distribution")
plt.show()

"""###**Print distributions**

**Training Data frame**
"""
# === 5. בדיקה של עמודות קטגוריאליות ומספריות ===
cat_cols = df_train.select_dtypes(include=['object']).columns.tolist()
num_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
# === 7. גרפים בסיסיים על פיצ'רים מספריים ===
for col in num_cols:
    plt.figure(figsize=(6,3))
    sns.histplot(df_train[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.show()

# === 8. גרפים בסיסיים על פיצ'רים קטגוריאליים ===
for col in cat_cols:
    plt.figure(figsize=(6,3))
    sns.countplot(x=col, data=df_train)
    plt.title(f'Distribution of {col}')
    plt.show()

"""**Test Data frame**"""

# === 5. בדיקה של עמודות קטגוריאליות ומספריות ===
cat_cols = df_test.select_dtypes(include=['object']).columns.tolist()
num_cols = df_test.select_dtypes(include=['int64', 'float64']).columns.tolist()
# === 7. גרפים בסיסיים על פיצ'רים מספריים ===
for col in num_cols:
    plt.figure(figsize=(6,3))
    sns.histplot(df_test[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.show()

# === 8. גרפים בסיסיים על פיצ'רים קטגוריאליים ===
for col in cat_cols:
    plt.figure(figsize=(6,3))
    sns.countplot(x=col, data=df_test)
    plt.title(f'Distribution of {col}')
    plt.show()

"""## Preproccesing"""

# === 3. target + features ===
target = "Churn"
X_train = df_train.drop(columns=[target])
y_train = df_train[target]

X_test = df_test.drop(columns=[target])
y_test = df_test[target]

# === 4. זיהוי קטגוריות ומספרים ===
cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()
num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()

print("Numeric:", num_cols)
print("Categorical:", cat_cols)

# # === 5. One-hot encoding לקטגוריות ===
# X_train = pd.get_dummies(X_train, columns=cat_cols, drop_first=True)
# X_test  = pd.get_dummies(X_test, columns=cat_cols, drop_first=True)

"""## **Standart Scaler + One hot encoding**

"""

# נוודא שהעמודות מתואמות בין train ל-test
X_train, X_test = X_train.align(X_test, join="left", axis=1, fill_value=0)

# # === 6. נרמול על המספרים ===
# scaler = StandardScaler()
# X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
# X_test[num_cols]  = scaler.transform(X_test[num_cols])


import joblib

# בניית הטרנספורמרים
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), cat_cols)])

# יצירת Pipeline המכיל רק את ה-preprocessor
preprocessor_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])

# אימון ה-preprocessor (fit)
preprocessor_pipeline.fit(X_train)
X_train = preprocessor_pipeline.transform(X_train)
X_test = preprocessor_pipeline.transform(X_test)

preprocessor_data = {
    "preprocessor": preprocessor_pipeline,
    "num_cols": num_cols,
    "cat_cols": cat_cols
}
joblib.dump(preprocessor_data, "../preprocessing/telecom/telecom_preprocessor_data.pkl")


"""## Train Model"""

# === 7. XGBoost training ===
model = xgb.XGBClassifier(
    n_estimators=450,
    learning_rate=0.01,
    max_depth=8,
    subsample=0.7,
    colsample_bytree=0.7,
    random_state=42,
    eval_metric='logloss',
    scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1])

)

eval_set = [(X_train, y_train), (X_test, y_test)]
model.fit(
    X_train, y_train,
    eval_set=eval_set,
    verbose=50
)

"""## Evaluation"""

# חיזוי הסתברויות
y_proba = model.predict_proba(X_test)[:, 1]

# נבחר threshold חדש
threshold = 0.4
y_pred_thresh = (y_proba >= threshold).astype(int)

print(f"--- תוצאות עם threshold = {threshold} ---")
print(classification_report(y_test, y_pred_thresh))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_thresh))

"""## LogLoss Train vs Test"""

# --- גרף logloss ---
results = model.evals_result()
plt.plot(results['validation_0']['logloss'], label='train')
plt.plot(results['validation_1']['logloss'], label='validation')
plt.xlabel('Iteration')
plt.ylabel('Logloss')
plt.title('XGBoost Logloss')
plt.legend()
plt.show()

import joblib

# נניח שהמודל שלך נקרא model
joblib.dump(model, "telecom.pkl")   # בדאטהסט הבנק