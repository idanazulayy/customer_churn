# -*- coding: utf-8 -*-
"""Bank customer churn ( XGBoost)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tzIIi1LUhbcSo4F-7ImQlNCOQqddM9Bk

# Customer churn - Bank

## import and settings
"""

import kagglehub
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.utils import resample
from sklearn.metrics import classification_report, confusion_matrix

"""**Plotty setting**"""

# Set Plotly as Pandas plotting backend

pd.options.plotting.backend = "plotly"
np.set_printoptions(precision=2, suppress=True)
pd.options.display.precision = 2
pd.options.display.float_format = '{:.2f}'.format

"""## Data collection"""

# Download latest version
path = kagglehub.dataset_download("gauravtopre/bank-customer-churn-dataset")

print("Path to dataset files:", path)

file_path = os.path.join(path, "Bank Customer Churn Prediction.csv")

# קריאה ל-DataFrame
df = pd.read_csv(file_path)

# הצגת מידע ראשוני
print(df.head())
print(df.info())
print(df.describe(include="all"))

"""### **Missing values**"""

# בדיקה של חוסרים
print("Missing values per column:")
print(df.isnull().sum())

"""### **Target values counter**"""

#  בדיקת חלוקת target 'Churn' ===
print("\nחלוקת target - Churn:")
print(df['churn'].value_counts())
# גרף חלוקת churn
sns.countplot(x='churn', data=df)
plt.title("Churn Distribution")
plt.show()

"""**Drop customerID - not relevant**"""

# זריקת customer_id
df = df.drop(columns=["customer_id"])

"""###**Print distributions**"""

# --- שלב 2: הגדרת target ופיצ’רים ---
target = "churn"
X = df.drop(columns=[target])
y = df[target]

# --- שלב 3: חלוקה לעמודות מספריות וקטגוריות ---
num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

print("Numeric:", num_cols)
print("Categorical:", cat_cols)

# גרפים בסיסיים על פיצ'רים מספריים
for col in num_cols:
    plt.figure(figsize=(6,3))
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.show()

# גרפים בסיסיים על פיצ'רים קטגוריאליים
for col in cat_cols:
    plt.figure(figsize=(6,3))
    sns.countplot(x=col, data=df)
    plt.title(f'Distribution of {col}')
    plt.show()

"""### **Correlation between Numberical features**"""

# קורלציה בין פיצ'רים מספריים
plt.figure(figsize=(10,6))
corr = df.corr(numeric_only=True)
plt.imshow(corr, cmap='coolwarm', interpolation='none')
plt.colorbar()
plt.xticks(range(len(corr)), corr.columns, rotation=90)
plt.yticks(range(len(corr)), corr.columns)
plt.title("Correlation Heatmap")
plt.show()

"""## Preproccesing"""

# --- שלב 4: בניית טרנספורמציות ---
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))
])

# --- שלב 5: חיבור הכל ל-ColumnTransformer ---
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, num_cols),
        ('cat', categorical_transformer, cat_cols)
    ]
)
# כאן נשמור את ה-preprocessor + columns
import joblib


"""### **Imbalance Taking care 1:2**"""

from sklearn.utils import resample


"""### **Split data to train / test**

"""

from sklearn.model_selection import train_test_split





# === 5. Train-test split ===
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# נפריד את המחלקות בתוך סט האימון בלבד
X_train_majority = X_train[y_train == 0]
y_train_majority = y_train[y_train == 0]

X_train_minority = X_train[y_train == 1]
y_train_minority = y_train[y_train == 1]

# נגדיל את minority כדי להגיע ליחס ~1:2
X_train_minority_upsampled, y_train_minority_upsampled = resample(
    X_train_minority, y_train_minority,
    replace=True,  # דגימה עם החזרה
    n_samples=int(len(X_train_majority) / 3.5),  # minority = חצי מגודל majority
    random_state=42
)

# נאחד חזרה
X_train_res = pd.concat([X_train_majority, X_train_minority_upsampled])
y_train_res = pd.concat([y_train_majority, y_train_minority_upsampled])

# נערבב
X_train_res, y_train_res = X_train_res.sample(frac=1, random_state=42).reset_index(drop=True), y_train_res.sample(frac=1, random_state=42).reset_index(drop=True)

print("לפני איזון:")
print(y_train.value_counts())
print("\nאחרי איזון:")
print(y_train_res.value_counts())

"""## **Train model**"""

from xgboost import XGBClassifier

# --- המרת X_train/X_test לאחר preprocessing ---
X_train_proc = preprocessor.fit_transform(X_train_res)
X_test_proc = preprocessor.transform(X_test)

preprocessor_data = {
    "preprocessor": preprocessor,
    "num_cols": num_cols,
    "cat_cols": cat_cols
}

joblib.dump(preprocessor_data, "../preprocessing/bank/bank_preprocessor_data.pkl")


# --- מודל XGB עם weight imbalance ---
# XGBClassifier רגיל
xgb_model = XGBClassifier(
    objective='binary:logistic',
    eval_metric=['logloss','auc'],
    use_label_encoder=False,
    n_estimators=1750,
    reg_lambda=1.0,
    reg_alpha=0.7,
    max_depth=7,
    learning_rate=0.001,
    subsample=0.8,
    colsample_bytree=0.6,
    scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),  # איזון בין מחלקות
    random_state=42
)

# אימון עם early stopping
xgb_model.fit(
    X_train_proc, y_train_res,
    eval_set=[(X_train_proc, y_train_res), (X_test_proc, y_test)],
    verbose=True
)

"""## Evaluation"""

y_pred = xgb_model.predict(X_test_proc)

print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# --- חישוב והדפסת ROC AUC ---
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# חיזוי הסתברויות עבור המחלקה החיובית (1)
y_pred_proba = xgb_model.predict_proba(X_test_proc)[:, 1]

print("ROC AUC:", roc_auc_score(y_test, y_pred_proba))

# --- ציור עקומת ROC ---
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, label="XGBoost (AUC = %.3f)" % roc_auc_score(y_test, y_pred_proba))
plt.plot([0,1],[0,1],"--", color="gray")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.title("ROC Curve")
plt.show()

"""## LogLoss train vs Test"""

# --- גרף logloss ---
results = xgb_model.evals_result()
plt.plot(results['validation_0']['logloss'], label='train')
plt.plot(results['validation_1']['logloss'], label='validation')
plt.xlabel('Iteration')
plt.ylabel('Logloss')
plt.title('XGBoost Logloss')
plt.legend()
plt.show()

joblib.dump(xgb_model, "../saved_models/bank.pkl")
